# this will be used when sending request for web servers to fetch pages.
email=echintha@indiana.edu, midconov@indiana.edu, msalim@cs.indiana.edu

# a comma separated list of seed urls. Do not leave space between two entries
 seed-urls=http://hot.blogrolling.com/,http://www.bloglines.com/blog/chinthaka,\
  http://www.digg.com,http://www.bloglines.com/topblogs,http://www.wisebread.com/top-100-most-popular-personal-finance-blogs,\
  http://www.bloogz.com/rank/,http://www.cuteoverload.com/,http://www.engadget.com,http://www.gizmodo.com,http://www.gizmodo.com,\
  http://www.huffingtonpost.com,http://www.lifehacker.com,http://postsecret.blogspot.com,http://www.dailykos.com,\
  http://arstechnica.com,http://michellemalkin.com,http://www.tmz.com,http://thinkprogress.org,http://yanxi.bokewu.com,\
  http://www.crooksandliars.com,http://googleblog.blogspot.com,http://fans.persianblog.com,http://radioblogclub.com,\
  http://sethgodin.typepad.com,http://www.beppegrillo.it,http://instapundit.com,http://www.kotaku.com,http://perezhilton.com,\
  http://gigazine.net,http://headrush.typepad.com,\


# this is where all the downloaded pages are stored
data-folder=Data

# maximum threads the crawler should employ to crawl
max-crawler-threads=1

# maximum number of blog processor that should be created
max-blog-processing-threads=1

# file to store the history of blog sites detected
blog-history=detected-blogs-history.txt

# this is where we will be logging all the messages
log-file=logs/blog-processing-%g.log





