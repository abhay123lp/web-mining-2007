# this will be used when sending request for web servers to fetch pages.
email=echintha@indiana.edu, midconov@indiana.edu, msalim@cs.indiana.edu

# a comma separated list of seed urls. Do not leave space between two entries
 seed-urls=http://hot.blogrolling.com/,http://www.bloglines.com/blog/chinthaka,http://www.digg.com,http://www.bloglines.com/topblogs,http://www.wisebread.com/top-100-most-popular-personal-finance-blogs,http://www.bloogz.com/rank/
#seed-urls=http://www.bloglines.com/blog/chinthaka

# this is the maximum number of pages to crawl. -1 indicates, we do not have a limit
max-pages=-1

# this is where all the downloaded pages are stored
data-folder=Data

# maximum threads the crawler should employ to crawl
max-threads=20

# maximum frontier size (-1 for no limit)
frontier-size=-1

# the folder to store collected blog information, when we are using file based storage system.
# most of the we will be using a database
blog-data-folder=BlogDataStorage

# file to store the history of pages crawled
crawl-history=history.txt

# file to store the history of blog sites detected
blog-history=detected-blogs-history.txt

# log of a few statistics - file updated every minute
statitics-file=stats.txt

# info on redirected pages
redirection-log=redirects.log

# this is where we will be logging all the messages
log-file=logs/blog-processing-%g.log





